version: "3.5"
services:
  main:
    build:
      context: ./
      dockerfile: Dockerfile      
    ports:
      - "8004:8000"
    depends_on:
      - inference-service
      # - webapp
  inference-service:
    build:
      context: ./inference_service
    environment:
      - AWS_PROFILE=default
    volumes:
      - ~/.aws/:/root/.aws:ro        
    ports:
      - "8005:8000"
  # webapp:
  #   build:
  #     context: ./webapp
  #   ports:
  #     - "8080:8000"
  triton:
    image: nvcr.io/nvidia/tritonserver:22.02-py3
    env_file:
      - .aws.env
    ports:
      - "8003:8000" # part 8000 http, 8001 GRPC, 8002 Metric Service
    command:
      [
        "tritonserver",
        "--model-repository=s3://aerial-detection-mlops4/model/Visdrone/Yolov7/triton-deploy/models/"
      ]